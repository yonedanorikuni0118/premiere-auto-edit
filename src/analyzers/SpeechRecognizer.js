import OpenAI from 'openai';
import fs from 'fs-extra';
import path from 'path';
import ffmpeg from 'fluent-ffmpeg';

/**
 * éŸ³å£°èªè­˜ã‚¯ãƒ©ã‚¹
 * OpenAI Whisper APIã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
 */
export class SpeechRecognizer {
  constructor(config) {
    this.config = config;
    this.openai = new OpenAI({
      apiKey: config.openai.apiKey,
      timeout: 120000, // 2åˆ†ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
      maxRetries: 2,
    });
    this.maxFileSize = 24 * 1024 * 1024; // 24MBï¼ˆ25MBåˆ¶é™ã«å¯¾ã—ã¦å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³ï¼‰
    this.chunkDuration = 600; // 10åˆ†ã”ã¨ã«åˆ†å‰²ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
  }

  /**
   * ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ãƒã‚§ãƒƒã‚¯
   * @param {string} filePath - ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
   * @returns {number} ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰
   */
  getFileSize(filePath) {
    return fs.statSync(filePath).size;
  }

  /**
   * éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²
   * @param {string} audioPath - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
   * @param {number} chunkDuration - ãƒãƒ£ãƒ³ã‚¯ã®é•·ã•ï¼ˆç§’ï¼‰
   * @returns {Promise<Array>} åˆ†å‰²ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹é…åˆ—
   */
  async splitAudioFile(audioPath, chunkDuration = this.chunkDuration) {
    console.log(`ğŸ”ª éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ä¸­... (${chunkDuration}ç§’ã”ã¨)`);

    const chunks = [];
    const outputDir = path.join(path.dirname(audioPath), 'chunks');
    await fs.ensureDir(outputDir);

    // éŸ³å£°ã®ç·æ™‚é–“ã‚’å–å¾—
    const duration = await this.getAudioDuration(audioPath);
    const numChunks = Math.ceil(duration / chunkDuration);

    console.log(`   ç·æ™‚é–“: ${duration.toFixed(2)}ç§’ â†’ ${numChunks}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²`);

    for (let i = 0; i < numChunks; i++) {
      const startTime = i * chunkDuration;
      const chunkPath = path.join(outputDir, `chunk_${i.toString().padStart(3, '0')}.wav`);

      await this.extractAudioChunk(audioPath, chunkPath, startTime, chunkDuration);
      chunks.push({
        path: chunkPath,
        index: i,
        startTime,
        endTime: Math.min(startTime + chunkDuration, duration),
      });

      console.log(`   âœ“ ãƒãƒ£ãƒ³ã‚¯ ${i + 1}/${numChunks} ä½œæˆå®Œäº†`);
    }

    return chunks;
  }

  /**
   * éŸ³å£°ã®é•·ã•ã‚’å–å¾—
   * @param {string} audioPath - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
   * @returns {Promise<number>} éŸ³å£°ã®é•·ã•ï¼ˆç§’ï¼‰
   */
  getAudioDuration(audioPath) {
    return new Promise((resolve, reject) => {
      ffmpeg.ffprobe(audioPath, (err, metadata) => {
        if (err) {
          reject(err);
        } else {
          resolve(metadata.format.duration);
        }
      });
    });
  }

  /**
   * éŸ³å£°ã®ä¸€éƒ¨ã‚’æŠ½å‡º
   * @param {string} inputPath - å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
   * @param {string} outputPath - å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
   * @param {number} startTime - é–‹å§‹æ™‚é–“ï¼ˆç§’ï¼‰
   * @param {number} duration - é•·ã•ï¼ˆç§’ï¼‰
   * @returns {Promise<void>}
   */
  extractAudioChunk(inputPath, outputPath, startTime, duration) {
    return new Promise((resolve, reject) => {
      ffmpeg(inputPath)
        .setStartTime(startTime)
        .setDuration(duration)
        .audioCodec('pcm_s16le')
        .audioChannels(1)
        .audioFrequency(16000)
        .output(outputPath)
        .on('end', () => resolve())
        .on('error', (err) => reject(err))
        .run();
    });
  }

  /**
   * éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰
   * @param {string} audioPath - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
   * @returns {Object} æ–‡å­—èµ·ã“ã—çµæœã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
   */
  async transcribe(audioPath) {
    console.log(`ğŸ¤ éŸ³å£°èªè­˜é–‹å§‹: ${audioPath}`);

    const fileSize = this.getFileSize(audioPath);
    const fileSizeMB = (fileSize / 1024 / 1024).toFixed(2);
    console.log(`   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: ${fileSizeMB}MB`);

    // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼š24MBã‚’è¶…ãˆã‚‹å ´åˆã¯åˆ†å‰²å‡¦ç†
    if (fileSize > this.maxFileSize) {
      console.log(`âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒåˆ¶é™ã‚’è¶…ãˆã¦ã„ã¾ã™ (${fileSizeMB}MB > 24MB)`);
      console.log(`ğŸ”„ è‡ªå‹•åˆ†å‰²ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™...`);
      return await this.transcribeWithSplitting(audioPath);
    }

    // é€šå¸¸ã®æ–‡å­—èµ·ã“ã—å‡¦ç†
    return await this.transcribeSingleFile(audioPath);
  }

  /**
   * å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—
   * @param {string} audioPath - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
   * @returns {Object} æ–‡å­—èµ·ã“ã—çµæœ
   */
  async transcribeSingleFile(audioPath) {
    const maxRetries = 3;
    let lastError;

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        if (attempt > 1) {
          console.log(`ğŸ”„ ãƒªãƒˆãƒ©ã‚¤ä¸­... (${attempt}/${maxRetries})`);
          await new Promise(resolve => setTimeout(resolve, 2000 * attempt)); // æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
        }

        // Whisper APIã§æ–‡å­—èµ·ã“ã—
        const transcription = await this.openai.audio.transcriptions.create({
          file: fs.createReadStream(audioPath),
          model: this.config.openai.model,
          language: this.config.openai.language,
          response_format: 'verbose_json',
          timestamp_granularities: ['segment'],
        });

        console.log(`âœ… æ–‡å­—èµ·ã“ã—å®Œäº†: ${transcription.text?.length || 0}æ–‡å­—`);

        return {
          text: transcription.text,
          segments: transcription.segments || [],
          words: transcription.words || [],
          language: transcription.language,
          duration: transcription.duration,
        };
      } catch (error) {
        lastError = error;
        console.error(`âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ ${attempt}/${maxRetries}):`, error.message);

        // ãƒªãƒˆãƒ©ã‚¤ä¸å¯èƒ½ãªã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å³åº§ã«çµ‚äº†
        if (error.status === 401 || error.status === 403) {
          console.error('âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼: API Keyã‚’ç¢ºèªã—ã¦ãã ã•ã„');
          throw error;
        }
        if (error.status === 413) {
          console.error('âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ (æœ€å¤§25MB)');
          throw error;
        }
      }
    }

    // ã™ã¹ã¦ã®ãƒªãƒˆãƒ©ã‚¤ãŒå¤±æ•—ã—ãŸå ´åˆ
    console.error(`âŒ ${maxRetries}å›ã®è©¦è¡Œå¾Œã‚‚å¤±æ•—ã—ã¾ã—ãŸ`);
    throw lastError;
  }

  /**
   * å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã—ã¦æ–‡å­—èµ·ã“ã—
   * @param {string} audioPath - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
   * @returns {Object} æ–‡å­—èµ·ã“ã—çµæœ
   */
  async transcribeWithSplitting(audioPath) {
    try {
      // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²
      const chunks = await this.splitAudioFile(audioPath);
      console.log(`ğŸ“ ${chunks.length}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †æ¬¡å‡¦ç†ã—ã¾ã™...`);

      const allSegments = [];
      const allWords = [];
      let fullText = '';
      let totalDuration = 0;

      // å„ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
      for (const chunk of chunks) {
        console.log(`\nğŸ¤ ãƒãƒ£ãƒ³ã‚¯ ${chunk.index + 1}/${chunks.length} ã‚’å‡¦ç†ä¸­...`);

        const result = await this.transcribeSingleFile(chunk.path);

        // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’èª¿æ•´ã—ã¦ãƒãƒ¼ã‚¸
        const adjustedSegments = result.segments.map(seg => ({
          ...seg,
          start: seg.start + chunk.startTime,
          end: seg.end + chunk.startTime,
        }));

        const adjustedWords = result.words.map(word => ({
          ...word,
          start: word.start + chunk.startTime,
          end: word.end + chunk.startTime,
        }));

        allSegments.push(...adjustedSegments);
        allWords.push(...adjustedWords);
        fullText += result.text + ' ';
        totalDuration = Math.max(totalDuration, chunk.endTime);

        // ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        await fs.remove(chunk.path);
      }

      // chunksãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
      const chunksDir = path.join(path.dirname(audioPath), 'chunks');
      await fs.remove(chunksDir);

      console.log(`\nâœ… å…¨ãƒãƒ£ãƒ³ã‚¯ã®æ–‡å­—èµ·ã“ã—å®Œäº†: ${fullText.length}æ–‡å­—`);

      return {
        text: fullText.trim(),
        segments: allSegments,
        words: allWords,
        language: chunks.length > 0 ? 'ja' : undefined,
        duration: totalDuration,
      };
    } catch (error) {
      console.error(`âŒ åˆ†å‰²å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:`, error.message);
      throw error;
    }
  }

  /**
   * ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒ†ãƒ­ãƒƒãƒ—ç”¨ã«æ•´å½¢
   * @param {Array} segments - Whisperã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé…åˆ—
   * @returns {Array} ãƒ†ãƒ­ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ [{text, start, end}]
   */
  formatSegmentsForCaptions(segments) {
    const captions = [];
    const maxCharsPerLine = this.config.caption.maxCharsPerLine;
    const minDuration = this.config.caption.minDisplayDuration;

    for (const segment of segments) {
      const text = segment.text.trim();
      const start = segment.start;
      const end = segment.end;
      const duration = end - start;

      // çŸ­ã™ãã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—
      if (duration < minDuration) {
        continue;
      }

      // é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²
      if (text.length > maxCharsPerLine) {
        const lines = this.splitTextIntoLines(text, maxCharsPerLine);
        const timePerChar = duration / text.length;

        let currentTime = start;
        for (const line of lines) {
          const lineDuration = line.length * timePerChar;
          captions.push({
            text: line,
            start: currentTime,
            end: currentTime + lineDuration,
            duration: lineDuration,
          });
          currentTime += lineDuration;
        }
      } else {
        captions.push({
          text,
          start,
          end,
          duration,
        });
      }
    }

    return captions;
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šæ–‡å­—æ•°ã§åˆ†å‰²
   */
  splitTextIntoLines(text, maxChars) {
    const lines = [];
    const sentences = text.split(/([ã€‚ã€ï¼ï¼Ÿ\n])/);
    let currentLine = '';

    for (const sentence of sentences) {
      if ((currentLine + sentence).length <= maxChars) {
        currentLine += sentence;
      } else {
        if (currentLine) {
          lines.push(currentLine);
        }
        currentLine = sentence;
      }
    }

    if (currentLine) {
      lines.push(currentLine);
    }

    // ãã‚Œã§ã‚‚é•·ã„å ´åˆã¯å¼·åˆ¶åˆ†å‰²
    return lines.flatMap(line => {
      if (line.length <= maxChars) {
        return [line];
      }
      const chunks = [];
      for (let i = 0; i < line.length; i += maxChars) {
        chunks.push(line.slice(i, i + maxChars));
      }
      return chunks;
    });
  }

  /**
   * ãƒ•ã‚£ãƒ©ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡º
   * @param {Array} words - å˜èªé…åˆ—
   * @returns {Array} ãƒ•ã‚£ãƒ©ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä½ç½® [{word, start, end}]
   */
  detectFillerWords(words) {
    const fillerWords = this.config.autoCut.fillerWords;
    const detected = [];

    for (const wordData of words) {
      const word = wordData.word || wordData.text;
      if (fillerWords.some(filler => word.includes(filler))) {
        detected.push({
          word,
          start: wordData.start,
          end: wordData.end,
        });
      }
    }

    return detected;
  }

  /**
   * è©±é€Ÿã‚’è¨ˆç®—ï¼ˆæ–‡å­—/ç§’ï¼‰
   */
  calculateSpeakingRate(segments) {
    if (!segments || segments.length === 0) return 0;

    let totalChars = 0;
    let totalDuration = 0;

    for (const segment of segments) {
      totalChars += segment.text.length;
      totalDuration += segment.end - segment.start;
    }

    return totalDuration > 0 ? totalChars / totalDuration : 0;
  }

  /**
   * çµ±åˆã•ã‚ŒãŸéŸ³å£°è§£æ
   */
  async analyzeSpeech(audioPath) {
    const transcription = await this.transcribe(audioPath);
    const captions = this.formatSegmentsForCaptions(transcription.segments);
    const fillerWords = this.detectFillerWords(transcription.words);
    const speakingRate = this.calculateSpeakingRate(transcription.segments);

    return {
      transcription,
      captions,
      fillerWords,
      speakingRate,
      stats: {
        totalWords: transcription.words.length,
        totalSegments: transcription.segments.length,
        totalCaptions: captions.length,
        fillerWordCount: fillerWords.length,
        speakingRate: speakingRate.toFixed(2),
      },
    };
  }
}
