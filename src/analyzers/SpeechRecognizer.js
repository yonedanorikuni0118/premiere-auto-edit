import OpenAI from 'openai';
import fs from 'fs-extra';
import path from 'path';

/**
 * éŸ³å£°èªè­˜ã‚¯ãƒ©ã‚¹
 * OpenAI Whisper APIã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
 */
export class SpeechRecognizer {
  constructor(config) {
    this.config = config;
    this.openai = new OpenAI({
      apiKey: config.openai.apiKey,
    });
  }

  /**
   * éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰
   * @param {string} audioPath - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
   * @returns {Object} æ–‡å­—èµ·ã“ã—çµæœã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
   */
  async transcribe(audioPath) {
    console.log(`ğŸ¤ éŸ³å£°èªè­˜é–‹å§‹: ${audioPath}`);

    try {
      // Whisper APIã§æ–‡å­—èµ·ã“ã—
      const transcription = await this.openai.audio.transcriptions.create({
        file: fs.createReadStream(audioPath),
        model: this.config.openai.model,
        language: this.config.openai.language,
        response_format: 'verbose_json',
        timestamp_granularities: ['word', 'segment'],
      });

      console.log(`âœ… æ–‡å­—èµ·ã“ã—å®Œäº†: ${transcription.text?.length || 0}æ–‡å­—`);

      return {
        text: transcription.text,
        segments: transcription.segments || [],
        words: transcription.words || [],
        language: transcription.language,
        duration: transcription.duration,
      };
    } catch (error) {
      console.error('âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:', error.message);
      throw error;
    }
  }

  /**
   * ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒ†ãƒ­ãƒƒãƒ—ç”¨ã«æ•´å½¢
   * @param {Array} segments - Whisperã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé…åˆ—
   * @returns {Array} ãƒ†ãƒ­ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ [{text, start, end}]
   */
  formatSegmentsForCaptions(segments) {
    const captions = [];
    const maxCharsPerLine = this.config.caption.maxCharsPerLine;
    const minDuration = this.config.caption.minDisplayDuration;

    for (const segment of segments) {
      const text = segment.text.trim();
      const start = segment.start;
      const end = segment.end;
      const duration = end - start;

      // çŸ­ã™ãã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—
      if (duration < minDuration) {
        continue;
      }

      // é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²
      if (text.length > maxCharsPerLine) {
        const lines = this.splitTextIntoLines(text, maxCharsPerLine);
        const timePerChar = duration / text.length;

        let currentTime = start;
        for (const line of lines) {
          const lineDuration = line.length * timePerChar;
          captions.push({
            text: line,
            start: currentTime,
            end: currentTime + lineDuration,
            duration: lineDuration,
          });
          currentTime += lineDuration;
        }
      } else {
        captions.push({
          text,
          start,
          end,
          duration,
        });
      }
    }

    return captions;
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šæ–‡å­—æ•°ã§åˆ†å‰²
   */
  splitTextIntoLines(text, maxChars) {
    const lines = [];
    const sentences = text.split(/([ã€‚ã€ï¼ï¼Ÿ\n])/);
    let currentLine = '';

    for (const sentence of sentences) {
      if ((currentLine + sentence).length <= maxChars) {
        currentLine += sentence;
      } else {
        if (currentLine) {
          lines.push(currentLine);
        }
        currentLine = sentence;
      }
    }

    if (currentLine) {
      lines.push(currentLine);
    }

    // ãã‚Œã§ã‚‚é•·ã„å ´åˆã¯å¼·åˆ¶åˆ†å‰²
    return lines.flatMap(line => {
      if (line.length <= maxChars) {
        return [line];
      }
      const chunks = [];
      for (let i = 0; i < line.length; i += maxChars) {
        chunks.push(line.slice(i, i + maxChars));
      }
      return chunks;
    });
  }

  /**
   * ãƒ•ã‚£ãƒ©ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡º
   * @param {Array} words - å˜èªé…åˆ—
   * @returns {Array} ãƒ•ã‚£ãƒ©ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä½ç½® [{word, start, end}]
   */
  detectFillerWords(words) {
    const fillerWords = this.config.autoCut.fillerWords;
    const detected = [];

    for (const wordData of words) {
      const word = wordData.word || wordData.text;
      if (fillerWords.some(filler => word.includes(filler))) {
        detected.push({
          word,
          start: wordData.start,
          end: wordData.end,
        });
      }
    }

    return detected;
  }

  /**
   * è©±é€Ÿã‚’è¨ˆç®—ï¼ˆæ–‡å­—/ç§’ï¼‰
   */
  calculateSpeakingRate(segments) {
    if (!segments || segments.length === 0) return 0;

    let totalChars = 0;
    let totalDuration = 0;

    for (const segment of segments) {
      totalChars += segment.text.length;
      totalDuration += segment.end - segment.start;
    }

    return totalDuration > 0 ? totalChars / totalDuration : 0;
  }

  /**
   * çµ±åˆã•ã‚ŒãŸéŸ³å£°è§£æ
   */
  async analyzeSpeech(audioPath) {
    const transcription = await this.transcribe(audioPath);
    const captions = this.formatSegmentsForCaptions(transcription.segments);
    const fillerWords = this.detectFillerWords(transcription.words);
    const speakingRate = this.calculateSpeakingRate(transcription.segments);

    return {
      transcription,
      captions,
      fillerWords,
      speakingRate,
      stats: {
        totalWords: transcription.words.length,
        totalSegments: transcription.segments.length,
        totalCaptions: captions.length,
        fillerWordCount: fillerWords.length,
        speakingRate: speakingRate.toFixed(2),
      },
    };
  }
}
