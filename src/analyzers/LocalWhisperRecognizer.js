import { exec } from 'child_process';
import { promisify } from 'util';
import fs from 'fs-extra';
import path from 'path';

const execAsync = promisify(exec);

/**
 * ãƒ­ãƒ¼ã‚«ãƒ«WhisperéŸ³å£°èªè­˜ã‚¯ãƒ©ã‚¹
 * ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚ŒãŸWhisperã‚’ä½¿ç”¨ï¼ˆOpenAI APIä¸è¦ï¼‰
 */
export class LocalWhisperRecognizer {
  constructor(config) {
    this.config = config;
    this.whisperPath = '/Users/norikuni/Library/Python/3.9/bin/whisper';
  }

  /**
   * éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰
   */
  async transcribe(audioPath) {
    console.log(`ğŸ¤ éŸ³å£°èªè­˜é–‹å§‹ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«Whisperï¼‰: ${audioPath}`);

    const outputDir = path.dirname(audioPath);
    const baseName = path.basename(audioPath, path.extname(audioPath));

    try {
      // FFmpegã®ãƒ‘ã‚¹ã‚’å–å¾—
      const ffmpegDir = path.resolve('./node_modules/@ffmpeg-installer/darwin-arm64');

      // Whisperã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œï¼ˆJSONå½¢å¼ã§å‡ºåŠ›ï¼‰
      // PATHã«FFmpegã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ 
      const command = `PATH="${ffmpegDir}:$PATH" ${this.whisperPath} "${audioPath}" \
        --model base \
        --language ja \
        --output_format json \
        --output_dir "${outputDir}"`;

      console.log('   å‡¦ç†ä¸­... (ã“ã‚Œã«ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)');

      const { stdout, stderr } = await execAsync(command, {
        maxBuffer: 1024 * 1024 * 10, // 10MB buffer
      });

      // JSONçµæœã‚’èª­ã¿è¾¼ã¿
      const jsonPath = path.join(outputDir, `${baseName}.json`);
      const result = await fs.readJson(jsonPath);

      console.log(`âœ… æ–‡å­—èµ·ã“ã—å®Œäº†: ${result.text?.length || 0}æ–‡å­—`);

      // OpenAI APIå½¢å¼ã«å¤‰æ›
      const segments = result.segments || [];
      const words = this.extractWords(segments);

      return {
        text: result.text,
        segments: segments.map(seg => ({
          text: seg.text,
          start: seg.start,
          end: seg.end,
        })),
        words: words,
        language: result.language || 'ja',
        duration: segments.length > 0 ? segments[segments.length - 1].end : 0,
      };
    } catch (error) {
      console.error('âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:', error.message);
      throw error;
    }
  }

  /**
   * ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰å˜èªã‚’æŠ½å‡º
   */
  extractWords(segments) {
    const words = [];

    for (const segment of segments) {
      // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å˜èªã«åˆ†å‰²
      const text = segment.text.trim();
      const wordTexts = text.split(/\s+/);

      if (wordTexts.length === 0) continue;

      const duration = segment.end - segment.start;
      const timePerWord = duration / wordTexts.length;

      for (let i = 0; i < wordTexts.length; i++) {
        words.push({
          word: wordTexts[i],
          start: segment.start + (i * timePerWord),
          end: segment.start + ((i + 1) * timePerWord),
        });
      }
    }

    return words;
  }

  /**
   * ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒ†ãƒ­ãƒƒãƒ—ç”¨ã«æ•´å½¢
   */
  formatSegmentsForCaptions(segments) {
    const captions = [];
    const maxCharsPerLine = this.config.caption.maxCharsPerLine;
    const minDuration = this.config.caption.minDisplayDuration;

    for (const segment of segments) {
      const text = segment.text.trim();
      const start = segment.start;
      const end = segment.end;
      const duration = end - start;

      if (duration < minDuration) {
        continue;
      }

      if (text.length > maxCharsPerLine) {
        const lines = this.splitTextIntoLines(text, maxCharsPerLine);
        const timePerChar = duration / text.length;

        let currentTime = start;
        for (const line of lines) {
          const lineDuration = line.length * timePerChar;
          captions.push({
            text: line,
            start: currentTime,
            end: currentTime + lineDuration,
            duration: lineDuration,
          });
          currentTime += lineDuration;
        }
      } else {
        captions.push({
          text,
          start,
          end,
          duration,
        });
      }
    }

    return captions;
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šæ–‡å­—æ•°ã§åˆ†å‰²
   */
  splitTextIntoLines(text, maxChars) {
    const lines = [];
    const sentences = text.split(/([ã€‚ã€ï¼ï¼Ÿ\n])/);
    let currentLine = '';

    for (const sentence of sentences) {
      if ((currentLine + sentence).length <= maxChars) {
        currentLine += sentence;
      } else {
        if (currentLine) {
          lines.push(currentLine);
        }
        currentLine = sentence;
      }
    }

    if (currentLine) {
      lines.push(currentLine);
    }

    return lines.flatMap(line => {
      if (line.length <= maxChars) {
        return [line];
      }
      const chunks = [];
      for (let i = 0; i < line.length; i += maxChars) {
        chunks.push(line.slice(i, i + maxChars));
      }
      return chunks;
    });
  }

  /**
   * ãƒ•ã‚£ãƒ©ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡º
   */
  detectFillerWords(words) {
    const fillerWords = this.config.autoCut.fillerWords;
    const detected = [];

    for (const wordData of words) {
      const word = wordData.word || wordData.text;
      if (fillerWords.some(filler => word.includes(filler))) {
        detected.push({
          word,
          start: wordData.start,
          end: wordData.end,
        });
      }
    }

    return detected;
  }

  /**
   * è©±é€Ÿã‚’è¨ˆç®—
   */
  calculateSpeakingRate(segments) {
    if (!segments || segments.length === 0) return 0;

    let totalChars = 0;
    let totalDuration = 0;

    for (const segment of segments) {
      totalChars += segment.text.length;
      totalDuration += segment.end - segment.start;
    }

    return totalDuration > 0 ? totalChars / totalDuration : 0;
  }

  /**
   * çµ±åˆã•ã‚ŒãŸéŸ³å£°è§£æ
   */
  async analyzeSpeech(audioPath) {
    const transcription = await this.transcribe(audioPath);
    const captions = this.formatSegmentsForCaptions(transcription.segments);
    const fillerWords = this.detectFillerWords(transcription.words);
    const speakingRate = this.calculateSpeakingRate(transcription.segments);

    return {
      transcription,
      captions,
      fillerWords,
      speakingRate,
      stats: {
        totalWords: transcription.words.length,
        totalSegments: transcription.segments.length,
        totalCaptions: captions.length,
        fillerWordCount: fillerWords.length,
        speakingRate: speakingRate.toFixed(2),
      },
    };
  }
}
